data:
  n_classes: 6
  size: 224
  train_fold: fold_1
  valid_fold: fold_2
  test_fold: fold_3
  batch_size: 4
  num_workers: 4
model:
  filters: [64, 256, 512, 1024, 2048]
  freeze_epochs: 10
  optim_lr: 0.0001
  optim_betas: [0.9, 0.999]
  optim_final_lr: 0.1
  optim_gamma: 0.001
  optim_eps: 0.00000001
  optim_weight_decay: 0
  optim_amsbound: False
  loss_beta: 0.3
  loss_gamma: 1.33
trainer:
  detect_anomaly: True
  accelerator: cpu
  devices: 1
  max_epochs: 150
  logger: True
  callbacks:
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        patience: 20
        verbose: True
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: trained_model
  enable_progress_bar: True
